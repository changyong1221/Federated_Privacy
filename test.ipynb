{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application of FL task\n",
    "from MLModel import *\n",
    "from FLModel import *\n",
    "from utils import *\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cnn_mnist(num_users):\n",
    "    data_train = datasets.MNIST(root=\"~/data/\", train=True, download=True, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))\n",
    "\n",
    "    data_test = datasets.MNIST(root=\"~/data/\", train=False, download=True, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))\n",
    "\n",
    "    # split MNIST (training set) into non-iid data sets\n",
    "    non_iid = []\n",
    "    user_dict = mnist_noniid(data_train, num_users)\n",
    "    for i in range(num_users):\n",
    "        idx = user_dict[i]\n",
    "        d = data_train.data[idx].float().unsqueeze(1)\n",
    "        targets = data_train.targets[idx].float()\n",
    "        non_iid.append((d, targets))\n",
    "    non_iid.append((data_test.data.float().unsqueeze(1), data_test.targets.float()))\n",
    "    return non_iid\n",
    "\n",
    "\n",
    "def load_mnist(num_users):\n",
    "    data_train = datasets.MNIST(root=\"~/data/\", train=True, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))\n",
    "\n",
    "    data_test = datasets.MNIST(root=\"~/data/\", train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))\n",
    "\n",
    "    # split MNIST (training set) into non-iid data sets\n",
    "    non_iid = []\n",
    "    user_dict = mnist_noniid(data_train, num_users)\n",
    "    for i in range(num_users):\n",
    "        idx = user_dict[i]\n",
    "        d = data_train.data[idx].flatten(1).float()\n",
    "        targets = data_train.targets[idx].float()\n",
    "        non_iid.append((d, targets))\n",
    "    non_iid.append((data_test.data.flatten(1).float(), data_test.targets.float()))\n",
    "    return non_iid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. load_data\n",
    "2. generate clients (step 3)\n",
    "3. generate aggregator\n",
    "4. training\n",
    "\"\"\"\n",
    "client_num = 10\n",
    "d = load_cnn_mnist(client_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DP-SGD with sampling rate = 5% and noise_multiplier = 2.489549708987475 iterated over 20000 steps satisfies differential privacy with eps = 16 and delta = 0.0001.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "FL model parameters.\n",
    "Note that 'eps' is the privacy budget for **each** global communication\n",
    "You may use composition theorems to compute the total privacy budget\n",
    "\"\"\"\n",
    "lr = 0.1\n",
    "fl_param = {\n",
    "    'output_size': 10,\n",
    "    'client_num': client_num,\n",
    "    'model': MnistCNN,\n",
    "    'data': d,\n",
    "    'lr': lr,\n",
    "    'E': 100,\n",
    "    'C': 1,\n",
    "    'eps': 16,\n",
    "    'delta': 1e-4,\n",
    "    'q': 0.05,\n",
    "    'clip': 12,\n",
    "    'tot_T': 10,\n",
    "    'batch_size': 64,\n",
    "    'device': device\n",
    "}\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "fl_entity = FLServer(fl_param).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist\n",
      "global epochs = 1, acc = 0.3859\n",
      "global epochs = 2, acc = 0.6777\n",
      "global epochs = 3, acc = 0.7663\n",
      "global epochs = 4, acc = 0.8120\n",
      "global epochs = 5, acc = 0.8794\n",
      "global epochs = 6, acc = 0.8838\n",
      "global epochs = 7, acc = 0.9107\n",
      "global epochs = 8, acc = 0.9211\n",
      "global epochs = 9, acc = 0.9190\n",
      "global epochs = 10, acc = 0.9367\n"
     ]
    }
   ],
   "source": [
    "print(\"mnist\")\n",
    "acc = []\n",
    "for e in range(fl_param['tot_T']):\n",
    "    fl_entity.set_lr(lr/np.sqrt(e+1))\n",
    "    acc += [fl_entity.global_update()]\n",
    "    print(\"global epochs = {:d}, acc = {:.4f}\".format(e+1, acc[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
